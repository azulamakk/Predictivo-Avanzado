{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450a321b",
   "metadata": {},
   "source": [
    "# INTRODUCCIÓN: EL PROCESO DE LA CIENCIA DE DATOS\n",
    "\n",
    "<img src=\"crisp.jpg\" align=\"center\" width=\"50%\"></img>\n",
    "\n",
    "El acrónimo CRISP-DM refiere a Proceso Estándar Cross Industria para la Minería de Datos (\"Cross Industry Standard Process for Data Mining\" en inglés) y fue introducido en 1996 en un esfuerzo de estandarizar el proceso de la minería de datos, de forma tal que pudiera servir como un flujo de trabajo estándar y confiable que pudiera ser adoptado por diferentes industrias. Dicho proceso serviría como el puntapié inicial para las *mejores prácticas* que produciría diversos beneficios.\n",
    "\n",
    "Además de otorgar un proceso consistente y confiable bajo el cual organizar los proyectos de minería de datos también generaría confianza en clientes y demás partes interesadas que buscaban utilizar la minería de datos en sus organizaciones.\n",
    "\n",
    "El marco CRISP-DM consta de 6 pasos principales:\n",
    "\n",
    "- **Comprensión del negocio**. Implica la comprensión de los objetivos y requisitos de un proyecto desde el punto de vista empresarial. Estas perspectivas de negocio se utilizan para averiguar qué problemas de negocio se pueden resolver mediante el uso de la minería de datos.\n",
    "- **Comprensión de los datos**. Esta fase nos permite familiarizarnos con los datos y esto implica la realización de análisis exploratorios de datos (Exploratory Data Analysis o **EDA**). Dicha exploración inicial de datos puede permitirnos averiguar qué subconjuntos de datos a utilizar para el modelado posterior, así como ayudar en la generación de hipótesis a explorar.\n",
    "- **Preparación de los datos**. Se puede considerar que esta es la fase del proceso de minería de datos que más tiempo consume, ya que implica una limpieza y un preprocesamiento rigurosos de los datos, así como el tratamiento de los datos que faltan. \n",
    "**Se dice que esta parte del proceso insume hasta un 80% del tiempo de todo el proceso**.\n",
    "- **Modelización**. Los datos preprocesados se utilizan para crear modelos en los que se emplean algoritmos de aprendizaje para realizar análisis multivariados.\n",
    "- **Evaluación**. Al llevar a cabo los 4 pasos mencionados, es importante evaluar los resultados obtenidos y revisar el proceso realizado hasta el momento para determinar si se cumplen o no los objetivos de negocio fijados inicialmente. Si se considera oportuno, puede ser necesario repetir algunos pasos (es un proceso iterativo). Cuando se considere que los resultados y el proceso son satisfactorios, estaremos listos para pasar a la implementación. Además, en esta fase de evaluación, algunos resultados pueden suscitar nuevas ideas de proyectos que explorar.\n",
    "- **Deployment**. Una vez que el modelo tiene una calidad satisfactoria, se procede a su deploy, que puede ser un simple informe, una API, una aplicación web, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af11f33",
   "metadata": {},
   "source": [
    "## Los roles en el proceso de ciencia de datos\n",
    "<img src=\"data science process.jpg\" align=\"center\" width=\"50%\"></img>\n",
    "\n",
    "A medida que la disciplina se fue desarrollando, fueron apariendo nuevos roles más especializados en el proceso. Los **ingenieros de datos** (data engineers) se encargan de las primeras etapas del proceso. Son quienes deben hacer la recolección y limpieza de los datos. Se especializan en el uso de bases de datos.\n",
    "\n",
    "Un segundo rol es el de los **analistas de datos** (data analysts). Se pueden superponer con los ingenieros de datos en la etapa de la limpieza de datos, pero van más allá y realizan análisis descriptivos de los conjuntos de datos (EDA). Pueden brindar valiosos *insights* para resolver los problemas planteados por el negocio/organización. De hecho, el resultado de su trabajo puede ser entregado a través de tableros o dashboards, en herramientas de BI como PowerBI, Tableau o Microstrategy.\n",
    "\n",
    "Por último, los **ingenieros de machine learning** (machine learning engineers o ML Ops) se encargan de la parte final del proceso. Pueden participar de la construcción de modelos, aunque su foco es más bien la última milla del proceso. Es decir, se encargan de la puesta en producción de modelos, típicamente en el contexto de la nube (AWS, Google Cloud, Microsoft Azure). Además, participan de la evaluación y supervisión de los modelos.\n",
    "\n",
    "Como vemos, el **científico de datos** tiene el rol más abarcativo. Debe ser capaz de cumplir todos los pasos del proceso, desde la formulación del problema o pregunta del negocio a resolver, hasta la implementación y evaluación del modelo que resuelva ese mismo problema formulado originalmente. Dependiendo de la organización, es posible que haya personas con uno o más de los roles anteriores, mientras que el resto del proceso típicamente es llevado a cabo por un científico de datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdbb963",
   "metadata": {},
   "source": [
    "# Tratamiento de variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464528f",
   "metadata": {},
   "source": [
    "### Variables Cualitativas y Cuantitativas\n",
    "\n",
    "---\n",
    "\n",
    "Las variables pueden ser caracterizadas como:\n",
    "\n",
    "* **cuantitativas**: \n",
    "\n",
    "    - Una variable cuantitativa toma valores numéricos, como en el caso de del ingreso de una persona o el precio de una casa.  \n",
    "<br>\n",
    "\n",
    "* **cualitativas**:  \n",
    "\n",
    "    - Una variable cualitativa toma valores en una de K diferentes clases o categorías.\n",
    "    - Una variable cualitativa con dos posibles valores se denomina **binaria o dicotómica**.\n",
    "\n",
    "### Tipos de una variable cualitativa\n",
    "\n",
    "\n",
    "#### Nominal/Categórica. Categorías nombradas.\n",
    "\n",
    "* Se suele asignar **valores o rótulos numéricos** a las variables categóricas: Estado civil, 0 si soltero y 1 si casado y 2 si divorciado\n",
    "\n",
    "* Los números utilizados para rotular son arbitrarios. \n",
    "\n",
    "* En general, el software asume que los valores numéricos reflejan cantidades algebraicas y, por tanto, un cierto orden.\n",
    "\n",
    "* La principal medida de posición es la **moda**. La mediana y la media no están definidas (y en general cualquier operación numérica tampoco).\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"cat1.png\" align=\"center\"></img>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Ordinal. \n",
    "\n",
    "* Es similar a una categórica pero existe un orden claro. \n",
    "\n",
    "<img src=\"cat2.png\" align=\"center\"></img>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "#### Una forma de representar las variables categóricas: las variables Dummies\n",
    "\n",
    "* Una **variable dummy** (variable indicadora) es una variable cualitativa que toma valores 0 o 1 para indicar la ausencia o presencia de algún atributo o efecto categórico\n",
    "\n",
    "* Formalmente una variable dummy puede ser expresada mediante una **función indicadora**:\n",
    "\n",
    "\\begin{equation}\n",
    "  D_i= \\mathbb{I}_A(x_i) = \\begin{cases}\n",
    "    1, & \\text{si $x_i \\in A$} \\\\    \n",
    "    0, & \\text{si $x_i \\not \\in A$}\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* ¿Cuál es la relación entre variables categóricas y variables dummies?\n",
    "\n",
    "    - Una variable categórica con N categorías puede ser expresada en términos de N−1 variables dummies (one-hot encoding).\n",
    "\n",
    "    - Resuelve el problema de interpretar las etiquetas numéricas como un intervalo.\n",
    "\n",
    "    - Este método tiene un **problema**: si las categorías tienen muchos valores aumenta considerablemente la **dimensionalidad** de los datos.\n",
    "\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "Supongamos que tenemos una variable categórica, C, que registra la ciudad en la que reside una muestra de habitantes de la Argentina.\n",
    "\n",
    "Asumamos que la variable puede tomar 4 posibles valores: Buenos Aires, Rosario, Córdoba y Mar del Plata.\n",
    "\n",
    "Imaginemos que tenemos las siguiente 5 observaciones:\n",
    "\n",
    "<img src=\"cat3.png\" align=\"center\"></img>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Podemos representar estas observaciones de la variable categórica usando dummies como:    \n",
    "\n",
    "<img src=\"cat4.png\" align=\"center\"></img>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Es importante notar que **si existen k categorías, k-1 variables dummies son suficientes para representarlas**. Es decir, la categoría k se puede inferir si todas las variables están en 0. En nuestro ejemplo, es el caso de Mar del Plata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491ab661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciudad</th>\n",
       "      <th>pais</th>\n",
       "      <th>clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paris</td>\n",
       "      <td>francia</td>\n",
       "      <td>positiva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paris</td>\n",
       "      <td>francia</td>\n",
       "      <td>negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tokyo</td>\n",
       "      <td>japón</td>\n",
       "      <td>negativa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amsterdam</td>\n",
       "      <td>países bajos</td>\n",
       "      <td>negativa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ciudad          pais     clase\n",
       "0      paris       francia  positiva\n",
       "1      paris       francia  negativa\n",
       "2      tokyo         japón  negativa\n",
       "3  amsterdam  países bajos  negativa"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from category_encoders import TargetEncoder\n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import pathlib\n",
    "import joblib \n",
    "\n",
    "from collections import defaultdict\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "\n",
    "df=pd.DataFrame({'ciudad': [\"paris\", \"paris\", \"tokyo\", \"amsterdam\"], 'pais': ['francia','francia','japón','países bajos'], 'clase':['positiva','negativa','negativa','negativa']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e467ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ciudad_paris</th>\n",
       "      <th>ciudad_tokyo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ciudad_paris  ciudad_tokyo\n",
       "0          True         False\n",
       "1          True         False\n",
       "2         False          True\n",
       "3         False         False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciudad_dummies = pd.get_dummies(df.ciudad, drop_first = True, prefix = 'ciudad')\n",
    "ciudad_dummies\n",
    "# Vemos que el registo n°3 corresponde a Amsterdam (ciudad_paris=F y ciudad_tokyo=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16271e",
   "metadata": {},
   "source": [
    "## Otra forma de codificar variables categóricas: LabelEncoder y OrdinalEncoder\n",
    "\n",
    "- LabelEncoder y OrdinalEncoder son similares: ordenan alfabéticamente las categorías y las codifican ordinalmente\n",
    "- Podemos utilizar LabelEncoder para codificar la respuesta Y, mientras que usamos OrdinalEncoder para codificar las variables X\n",
    "- No nos sirven para regresiones, pero nos sirven para algoritmos como el XGBoost, ya que sckit-learn requiere que todas las variables input sean numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dcc1402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negativa' 'positiva']\n",
      "[1 0 0 0]\n",
      "[1 0 0 0]\n",
      "[1 1 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df.clase)\n",
    "#Vemos las categorías ordenadas\n",
    "print(le.classes_)\n",
    "\n",
    "#Transformamos la variable\n",
    "print(le.transform(df.clase))\n",
    "\n",
    "#También podemos hacer todo junto\n",
    "print(le.fit_transform(df.clase))\n",
    "\n",
    "#Lo aplicamos a otros datos\n",
    "print(le.transform([\"positiva\", \"positiva\", \"negativa\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f36db4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [2. 1. 0.]\n",
      " [0. 2. 0.]]\n",
      "[array(['amsterdam', 'paris', 'tokyo'], dtype=object), array(['francia', 'japón', 'países bajos'], dtype=object), array(['negativa', 'positiva'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "enc = OrdinalEncoder()\n",
    "print(enc.fit_transform(df))\n",
    "print(enc.categories_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2537b9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe05c99",
   "metadata": {},
   "source": [
    "## Frequency Encoder\n",
    "\n",
    "- La idea es reemplazar cada categoría por la frecuencia de la categoría.\n",
    "- Para ello podemos utilizar la clase CountFrequencyEncoder de feature_engine.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc495b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9381abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0           1      3    male   NaN      1      1  15.2458        C\n",
       "1           0      2    male  31.0      0      0  10.5000        S\n",
       "2           0      3    male  20.0      0      0   7.9250        S\n",
       "3           1      2  female   6.0      0      1  33.0000        S\n",
       "4           1      3  female  14.0      1      0  11.2417        C\n",
       "..        ...    ...     ...   ...    ...    ...      ...      ...\n",
       "174         0      3    male  17.0      0      0   7.1250        S\n",
       "175         0      3    male   NaN      0      0   7.2250        C\n",
       "176         1      3  female  38.0      1      5  31.3875        S\n",
       "177         1      2  female  17.0      0      0  10.5000        S\n",
       "178         1      3  female   4.0      1      1  16.7000        S\n",
       "\n",
       "[179 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/Titanic/train.csv')\n",
    "\n",
    "for col in ['Sex','Pclass','Embarked']:\n",
    "    df[col] = df[col].astype('object')\n",
    "#Atención! Pclass es númerica pero debemos tratarla como categórica\n",
    "    \n",
    "df.loc[:,['Cabin','Embarked']]=df.loc[:,['Cabin','Embarked']].fillna('NA')\n",
    "df=df.drop(columns=['PassengerId','Name','Ticket','Cabin'])\n",
    "\n",
    "# X=df.drop(columns=['PassengerId','Survived','Name','Ticket','Cabin'])\n",
    "# y=train['Survived']\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# X_train.reset_index(inplace=True,drop=True)\n",
    "# X_test.reset_index(inplace=True,drop=True)\n",
    "# y_train.reset_index(inplace=True,drop=True)\n",
    "# y_test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9e4e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "male      0.655899\n",
       "female    0.344101\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sex.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0b9968a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65589888],\n",
       "       [0.65589888],\n",
       "       [0.65589888],\n",
       "       [0.65589888],\n",
       "       [0.34410112],\n",
       "       [0.65589888],\n",
       "       [0.65589888],\n",
       "       [0.65589888],\n",
       "       [0.65589888],\n",
       "       [0.65589888]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Genero diccionario de Frequency Encoders\n",
    "dict_encoders_freq = defaultdict(CountFrequencyEncoder)\n",
    "\n",
    "frecuency_transformer = CountFrequencyEncoder(encoding_method='frequency',missing_values='ignore')\n",
    "# target_encoder = TargetEncoder()\n",
    "\n",
    "vars_cat=['Sex']\n",
    "var_clase='Survived'\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "transformers=[\n",
    "('frecuency_transformer', frecuency_transformer, vars_cat),\n",
    "],remainder='passthrough') \n",
    "\n",
    "train_features = preprocess.fit_transform(train[vars_cat],train[var_clase])\n",
    "\n",
    "#Vemos que reemplazó las categorías por la frecuencia\n",
    "\n",
    "train_features[:10]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd512b4",
   "metadata": {},
   "source": [
    "## Target Encoder\n",
    "\n",
    "- La idea es reemplazar cada categoría por la proporción de la clase positiva de la variable target (en problemas de clasificación) o bien por su valor medio (en problemas de regresión).\n",
    "- Para ello podemos utilizar la clase TargetEncoder de category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "072c3b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Survived</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.261224</td>\n",
       "      <td>0.738776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.813704</td>\n",
       "      <td>0.186296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Survived         0         1\n",
       "Sex                         \n",
       "female    0.261224  0.738776\n",
       "male      0.813704  0.186296"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Analicemos \n",
    "pd.crosstab(train.Sex,train.Survived,normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10f82b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1862955 ],\n",
       "       [0.1862955 ],\n",
       "       [0.1862955 ],\n",
       "       [0.1862955 ],\n",
       "       [0.73877551],\n",
       "       [0.1862955 ],\n",
       "       [0.1862955 ],\n",
       "       [0.1862955 ],\n",
       "       [0.1862955 ],\n",
       "       [0.1862955 ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Genero diccionario de Frequency Encoders\n",
    "dict_encoders_freq = defaultdict(CountFrequencyEncoder)\n",
    "\n",
    "# frecuency_transformer = CountFrequencyEncoder(encoding_method='frequency',missing_values='ignore')\n",
    "target_encoder = TargetEncoder()\n",
    "\n",
    "vars_cat=['Sex']\n",
    "var_clase='Survived'\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "transformers=[\n",
    "('target_encoder', target_encoder, vars_cat)\n",
    "],remainder='passthrough') \n",
    "\n",
    "train_features = preprocess.fit_transform(train[vars_cat],train[var_clase])\n",
    "\n",
    "#Vemos que reemplazó las categorías por la proporción de la clase positiva\n",
    "train_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "599801d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Podemos integrar todas las codificaciones en una sola función, y aplicarla siempre que tengamos variables categóricas\n",
    "\n",
    "def trans_factores (df,vars_cat,var_clase):\n",
    "\n",
    "    ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "    frecuency_transformer = CountFrequencyEncoder(encoding_method='frequency')\n",
    "    target_encoder = TargetEncoder()\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "    ('ordinal_encoder', ordinal_encoder, vars_cat),\n",
    "    ('frecuency_transformer', frecuency_transformer, vars_cat),\n",
    "    ('target_encoder', target_encoder, vars_cat)\n",
    "    ],remainder='passthrough') \n",
    "\n",
    "    train_features = preprocess.fit_transform(df[vars_cat],df[var_clase])\n",
    "\n",
    "    #Guardamos archivo con encodings de los transformadores, a fin de poder utilizarlos en \n",
    "    #futuras corridas productivas\n",
    "    pathlib.Path(f\"preprocessing\").mkdir(parents=True, exist_ok=True)\n",
    "    _=joblib.dump(preprocess, 'preprocessing/transformer.joblib')\n",
    "    \n",
    "    #Renombramos variables codificadas\n",
    "    vars_cat_cols=[s + '_ordinal' for s in vars_cat]\n",
    "    vars_cat_cols=vars_cat_cols+[s + '_freq' for s in vars_cat]\n",
    "    vars_cat_cols=vars_cat_cols+[s + '_target' for s in vars_cat]\n",
    "    df2=df.copy()\n",
    "    df2.drop(columns=vars_cat,axis=1,inplace=True)\n",
    "    df2=pd.concat([df2,pd.DataFrame(train_features,columns=vars_cat_cols)],axis=1)\n",
    "    return(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d785139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_ordinal</th>\n",
       "      <th>Pclass_ordinal</th>\n",
       "      <th>Embarked_ordinal</th>\n",
       "      <th>Sex_freq</th>\n",
       "      <th>Pclass_freq</th>\n",
       "      <th>Embarked_freq</th>\n",
       "      <th>Sex_target</th>\n",
       "      <th>Pclass_target</th>\n",
       "      <th>Embarked_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.228933</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.483443</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.228933</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.228933</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.228933</td>\n",
       "      <td>0.73736</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.607362</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived   Age  SibSp  Parch      Fare  Sex_ordinal  Pclass_ordinal  \\\n",
       "0           0  45.5      0      0   28.5000          1.0             0.0   \n",
       "1           0  23.0      0      0   13.0000          1.0             1.0   \n",
       "2           0  32.0      0      0    7.9250          1.0             2.0   \n",
       "3           0  26.0      1      0    7.8542          1.0             2.0   \n",
       "4           0   6.0      4      2   31.2750          0.0             2.0   \n",
       "..        ...   ...    ...    ...       ...          ...             ...   \n",
       "707         1  21.0      0      0    7.6500          0.0             2.0   \n",
       "708         0   NaN      0      0   31.0000          1.0             0.0   \n",
       "709         0  41.0      2      0   14.1083          1.0             2.0   \n",
       "710         1  14.0      1      2  120.0000          0.0             0.0   \n",
       "711         0  21.0      0      1   77.2875          1.0             0.0   \n",
       "\n",
       "     Embarked_ordinal  Sex_freq  Pclass_freq  Embarked_freq  Sex_target  \\\n",
       "0                 3.0  0.655899     0.228933        0.73736    0.186296   \n",
       "1                 3.0  0.655899     0.212079        0.73736    0.186296   \n",
       "2                 3.0  0.655899     0.558989        0.73736    0.186296   \n",
       "3                 3.0  0.655899     0.558989        0.73736    0.186296   \n",
       "4                 3.0  0.344101     0.558989        0.73736    0.738776   \n",
       "..                ...       ...          ...            ...         ...   \n",
       "707               3.0  0.344101     0.558989        0.73736    0.738776   \n",
       "708               3.0  0.655899     0.228933        0.73736    0.186296   \n",
       "709               3.0  0.655899     0.558989        0.73736    0.186296   \n",
       "710               3.0  0.344101     0.228933        0.73736    0.738776   \n",
       "711               3.0  0.655899     0.228933        0.73736    0.186296   \n",
       "\n",
       "     Pclass_target  Embarked_target  \n",
       "0         0.607362         0.335238  \n",
       "1         0.483443         0.335238  \n",
       "2         0.241206         0.335238  \n",
       "3         0.241206         0.335238  \n",
       "4         0.241206         0.335238  \n",
       "..             ...              ...  \n",
       "707       0.241206         0.335238  \n",
       "708       0.607362         0.335238  \n",
       "709       0.241206         0.335238  \n",
       "710       0.607362         0.335238  \n",
       "711       0.607362         0.335238  \n",
       "\n",
       "[712 rows x 14 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_cat=['Sex','Pclass','Embarked']\n",
    "train_mod=trans_factores(train,vars_cat,var_clase)\n",
    "train_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe0b8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_ordinal</th>\n",
       "      <th>Pclass_ordinal</th>\n",
       "      <th>Embarked_ordinal</th>\n",
       "      <th>Sex_freq</th>\n",
       "      <th>Pclass_freq</th>\n",
       "      <th>Embarked_freq</th>\n",
       "      <th>Sex_target</th>\n",
       "      <th>Pclass_target</th>\n",
       "      <th>Embarked_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.175562</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.543995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.483443</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.483443</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.175562</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.543995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655899</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.175562</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.543995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.212079</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.483443</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.344101</td>\n",
       "      <td>0.558989</td>\n",
       "      <td>0.737360</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.241206</td>\n",
       "      <td>0.335238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived   Age  SibSp  Parch     Fare  Sex_ordinal  Pclass_ordinal  \\\n",
       "0           1   NaN      1      1  15.2458          1.0             2.0   \n",
       "1           0  31.0      0      0  10.5000          1.0             1.0   \n",
       "2           0  20.0      0      0   7.9250          1.0             2.0   \n",
       "3           1   6.0      0      1  33.0000          0.0             1.0   \n",
       "4           1  14.0      1      0  11.2417          0.0             2.0   \n",
       "..        ...   ...    ...    ...      ...          ...             ...   \n",
       "174         0  17.0      0      0   7.1250          1.0             2.0   \n",
       "175         0   NaN      0      0   7.2250          1.0             2.0   \n",
       "176         1  38.0      1      5  31.3875          0.0             2.0   \n",
       "177         1  17.0      0      0  10.5000          0.0             1.0   \n",
       "178         1   4.0      1      1  16.7000          0.0             2.0   \n",
       "\n",
       "     Embarked_ordinal  Sex_freq  Pclass_freq  Embarked_freq  Sex_target  \\\n",
       "0                 0.0  0.655899     0.558989       0.175562    0.186296   \n",
       "1                 3.0  0.655899     0.212079       0.737360    0.186296   \n",
       "2                 3.0  0.655899     0.558989       0.737360    0.186296   \n",
       "3                 3.0  0.344101     0.212079       0.737360    0.738776   \n",
       "4                 0.0  0.344101     0.558989       0.175562    0.738776   \n",
       "..                ...       ...          ...            ...         ...   \n",
       "174               3.0  0.655899     0.558989       0.737360    0.186296   \n",
       "175               0.0  0.655899     0.558989       0.175562    0.186296   \n",
       "176               3.0  0.344101     0.558989       0.737360    0.738776   \n",
       "177               3.0  0.344101     0.212079       0.737360    0.738776   \n",
       "178               3.0  0.344101     0.558989       0.737360    0.738776   \n",
       "\n",
       "     Pclass_target  Embarked_target  \n",
       "0         0.241206         0.543995  \n",
       "1         0.483443         0.335238  \n",
       "2         0.241206         0.335238  \n",
       "3         0.483443         0.335238  \n",
       "4         0.241206         0.543995  \n",
       "..             ...              ...  \n",
       "174       0.241206         0.335238  \n",
       "175       0.241206         0.543995  \n",
       "176       0.241206         0.335238  \n",
       "177       0.483443         0.335238  \n",
       "178       0.241206         0.335238  \n",
       "\n",
       "[179 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aplicamos transformer a test\n",
    "\n",
    "preprocess = joblib.load('preprocessing/transformer.joblib')\n",
    "test_features = preprocess.transform(test[vars_cat])\n",
    "\n",
    "vars_cat_cols=[s + '_ordinal' for s in vars_cat]\n",
    "vars_cat_cols=vars_cat_cols+[s + '_freq' for s in vars_cat]\n",
    "vars_cat_cols=vars_cat_cols+[s + '_target' for s in vars_cat]\n",
    "test_mod=pd.concat([test,pd.DataFrame(test_features,columns=vars_cat_cols)],axis=1)\n",
    "test_mod.drop(columns=vars_cat,axis=1,inplace=True)\n",
    "test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca34ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FVeliz\\AppData\\Local\\miniconda3\\envs\\itba_apa_env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_NA</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived   Age  SibSp  Parch      Fare  Sex_male  Pclass_2  Pclass_3  \\\n",
       "0           0  45.5      0      0   28.5000       1.0       0.0       0.0   \n",
       "1           0  23.0      0      0   13.0000       1.0       1.0       0.0   \n",
       "2           0  32.0      0      0    7.9250       1.0       0.0       1.0   \n",
       "3           0  26.0      1      0    7.8542       1.0       0.0       1.0   \n",
       "4           0   6.0      4      2   31.2750       0.0       0.0       1.0   \n",
       "..        ...   ...    ...    ...       ...       ...       ...       ...   \n",
       "707         1  21.0      0      0    7.6500       0.0       0.0       1.0   \n",
       "708         0   NaN      0      0   31.0000       1.0       0.0       0.0   \n",
       "709         0  41.0      2      0   14.1083       1.0       0.0       1.0   \n",
       "710         1  14.0      1      2  120.0000       0.0       0.0       0.0   \n",
       "711         0  21.0      0      1   77.2875       1.0       0.0       0.0   \n",
       "\n",
       "     Embarked_NA  Embarked_Q  Embarked_S  \n",
       "0            0.0         0.0         1.0  \n",
       "1            0.0         0.0         1.0  \n",
       "2            0.0         0.0         1.0  \n",
       "3            0.0         0.0         1.0  \n",
       "4            0.0         0.0         1.0  \n",
       "..           ...         ...         ...  \n",
       "707          0.0         0.0         1.0  \n",
       "708          0.0         0.0         1.0  \n",
       "709          0.0         0.0         1.0  \n",
       "710          0.0         0.0         1.0  \n",
       "711          0.0         0.0         1.0  \n",
       "\n",
       "[712 rows x 11 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probamos con OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(drop='first',sparse=False)\n",
    "train_onehot = encoder.fit_transform(train[vars_cat])\n",
    "train_onehot=pd.DataFrame(train_onehot,columns=encoder.get_feature_names_out())\n",
    "#¿Cúantas variables debería generar el encoder?\n",
    "\n",
    "train_ohe=pd.concat([train,train_onehot],axis=1)\n",
    "train_ohe.drop(columns=vars_cat,inplace=True)\n",
    "train_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7bb5019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_NA</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived   Age  SibSp  Parch     Fare  Sex_male  Pclass_2  Pclass_3  \\\n",
       "0           1   NaN      1      1  15.2458       1.0       0.0       1.0   \n",
       "1           0  31.0      0      0  10.5000       1.0       1.0       0.0   \n",
       "2           0  20.0      0      0   7.9250       1.0       0.0       1.0   \n",
       "3           1   6.0      0      1  33.0000       0.0       1.0       0.0   \n",
       "4           1  14.0      1      0  11.2417       0.0       0.0       1.0   \n",
       "..        ...   ...    ...    ...      ...       ...       ...       ...   \n",
       "174         0  17.0      0      0   7.1250       1.0       0.0       1.0   \n",
       "175         0   NaN      0      0   7.2250       1.0       0.0       1.0   \n",
       "176         1  38.0      1      5  31.3875       0.0       0.0       1.0   \n",
       "177         1  17.0      0      0  10.5000       0.0       1.0       0.0   \n",
       "178         1   4.0      1      1  16.7000       0.0       0.0       1.0   \n",
       "\n",
       "     Embarked_NA  Embarked_Q  Embarked_S  \n",
       "0            0.0         0.0         0.0  \n",
       "1            0.0         0.0         1.0  \n",
       "2            0.0         0.0         1.0  \n",
       "3            0.0         0.0         1.0  \n",
       "4            0.0         0.0         0.0  \n",
       "..           ...         ...         ...  \n",
       "174          0.0         0.0         1.0  \n",
       "175          0.0         0.0         0.0  \n",
       "176          0.0         0.0         1.0  \n",
       "177          0.0         0.0         1.0  \n",
       "178          0.0         0.0         1.0  \n",
       "\n",
       "[179 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_onehot = encoder.transform(test[vars_cat])\n",
    "test_onehot=pd.DataFrame(test_onehot,columns=encoder.get_feature_names_out())\n",
    "\n",
    "test_ohe=pd.concat([test,test_onehot],axis=1)\n",
    "test_ohe.drop(columns=vars_cat,inplace=True)\n",
    "test_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c38bc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos utilizar solos las variables target\n",
    "train_target=train_mod.loc[:,train_mod.columns[train_mod.columns.str.contains('target|Survived')]]\n",
    "test_target=test_mod.loc[:,test_mod.columns[test_mod.columns.str.contains('target|Survived')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686b6fc",
   "metadata": {},
   "source": [
    "Entrenamos modelos con hiperparámetros por default..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d28571",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "y_train=train['Survived']\n",
    "y_test=test['Survived']\n",
    "\n",
    "X_train=train.drop(columns=['Survived']+vars_cat)\n",
    "X_test=test.drop(columns=['Survived']+vars_cat)\n",
    "model_xgb = XGBClassifier(n_jobs=3)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "\n",
    "X_train_mod=train_mod.drop(columns=['Survived'])\n",
    "X_test_mod=test_mod.drop(columns=['Survived'])\n",
    "model_xgb_mod = XGBClassifier(n_jobs=3)\n",
    "model_xgb_mod.fit(X_train_mod,y_train)\n",
    "\n",
    "X_train_ohe=train_ohe.drop(columns=['Survived'])\n",
    "X_test_ohe=test_ohe.drop(columns=['Survived'])\n",
    "model_xgb_ohe = XGBClassifier(n_jobs=3)\n",
    "model_xgb_ohe.fit(X_train_ohe,y_train)\n",
    "\n",
    "X_train_target=train_target.drop(columns=['Survived'])\n",
    "X_test_target=test_target.drop(columns=['Survived'])\n",
    "model_xgb_target = XGBClassifier(n_jobs=3)\n",
    "model_xgb_target.fit(X_train_target,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce960c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test sin vars cat: 0.65\n",
      "AUC test One-Hot Encoding: 0.81\n",
      "AUC test DF Nuevo Feature Engineering: 0.81\n",
      "AUC test Solo FE Target: 0.77\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred=model_xgb.predict(X_test)\n",
    "print(f'AUC test sin vars cat: {round(roc_auc_score(y_test,y_pred),2)}')\n",
    "\n",
    "y_pred=model_xgb_ohe.predict(X_test_ohe)\n",
    "print(f'AUC test One-Hot Encoding: {round(roc_auc_score(y_test,y_pred),2)}')\n",
    "\n",
    "y_pred=model_xgb_mod.predict(X_test_mod)\n",
    "print(f'AUC test DF Nuevo Feature Engineering: {round(roc_auc_score(y_test,y_pred),2)}')\n",
    "\n",
    "y_pred=model_xgb_target.predict(X_test_target)\n",
    "print(f'AUC test Solo FE Target: {round(roc_auc_score(y_test,y_pred),2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10d560",
   "metadata": {},
   "source": [
    "- Obtenemos ventajas al agregar las variables categóricas, pero no parece haber diferencia entre One-Hot Encoding y la variante de Feature Engineering propuesta.\n",
    "- Si dejamos solo el Target Encoding, la performance decae.\n",
    "\n",
    "### ¿Qué pasaría si tuvieramos una base más chica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41107697",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f=train.sample(100,random_state=42)\n",
    "train_mod_f=train_mod.sample(100,random_state=42)\n",
    "train_ohe_f=train_ohe.sample(100,random_state=42)\n",
    "train_target_f=train_target.sample(100,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51534bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "y_train=train_f['Survived']\n",
    "y_test=test['Survived']\n",
    "\n",
    "X_train=train_f.drop(columns=['Survived']+vars_cat)\n",
    "X_test=test.drop(columns=['Survived']+vars_cat)\n",
    "model_xgb = XGBClassifier(n_jobs=3)\n",
    "model_xgb.fit(X_train,y_train)\n",
    "\n",
    "X_train_mod=train_mod_f.drop(columns=['Survived'])\n",
    "X_test_mod=test_mod.drop(columns=['Survived'])\n",
    "model_xgb_mod = XGBClassifier(n_jobs=3)\n",
    "model_xgb_mod.fit(X_train_mod,y_train)\n",
    "\n",
    "X_train_ohe=train_ohe_f.drop(columns=['Survived'])\n",
    "X_test_ohe=test_ohe.drop(columns=['Survived'])\n",
    "model_xgb_ohe = XGBClassifier(n_jobs=3)\n",
    "model_xgb_ohe.fit(X_train_ohe,y_train)\n",
    "\n",
    "X_train_target=train_target_f.drop(columns=['Survived'])\n",
    "X_test_target=test_target.drop(columns=['Survived'])\n",
    "model_xgb_target = XGBClassifier(n_jobs=3)\n",
    "model_xgb_target.fit(X_train_target,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80d703ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC test DF original: 0.71\n",
      "AUC test DF original: 0.72\n",
      "AUC test DF original: 0.73\n"
     ]
    }
   ],
   "source": [
    "y_pred=model_xgb_ohe.predict(X_test_ohe)\n",
    "print(f'AUC test DF original: {round(roc_auc_score(y_test,y_pred),2)}')\n",
    "\n",
    "y_pred=model_xgb_mod.predict(X_test_mod)\n",
    "print(f'AUC test DF original: {round(roc_auc_score(y_test,y_pred),2)}')\n",
    "\n",
    "y_pred=model_xgb_target.predict(X_test_target)\n",
    "print(f'AUC test DF original: {round(roc_auc_score(y_test,y_pred),2)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54826f",
   "metadata": {},
   "source": [
    "- El efecto a favor de la nueva forma de codificar las variables categóricas se ve mejor cuando hay un mal ratio entre cantidad categorías y cantidad de registros (variables con muchas categorías y/o pocos casos).\n",
    "- Es decir, podemos evitar caer en la **maldición de la dimensionalidad** a partir de las nuevas técnicas de feature engineering.\n",
    "- Para debatir. ¿Qué problema piensan que tendríamos si hicieramos Frequency Encoding o Target Encoding con Cross-Validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6065b52",
   "metadata": {},
   "source": [
    "## PRÁCTICA EN CLASE\n",
    "\n",
    "A partir del dataset MovieLens_1000.csv, entrenar tres modelos:\n",
    "1. Uno con one-hot encoding\n",
    "2. Otro aplicando las técnicas de feature engineering vistas\n",
    "3. Un tercero dejando unicamente las variables de target encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "003719d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a74ae342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>4</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating Gender  Age  Occupation\n",
       "0         4      M   35          15\n",
       "1         3      M   25          12\n",
       "2         4      F   35           1\n",
       "3         3      M   50           1\n",
       "4         4      M   35          12\n",
       "..      ...    ...  ...         ...\n",
       "995       5      M   25           6\n",
       "996       4      M   45          18\n",
       "997       3      M   50          11\n",
       "998       4      F   25           6\n",
       "999       3      M   18           0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_practica_f=pd.read_csv('data/MovieLens_1000.csv')\n",
    "df_practica_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d1469",
   "metadata": {},
   "source": [
    "## BIBLIOGRAFÍA\n",
    "\n",
    "- https://towardsdatascience.com/the-data-science-process-a19eb7ebc41b\n",
    "- https://machinelearningmastery.com/one-hot-encoding-for-categorical-data/\n",
    "- https://towardsdatascience.com/dealing-with-categorical-variables-by-using-target-encoder-a0f1733a4c69\n",
    "- https://towardsdatascience.com/feature-encoding-techniques-in-machine-learning-with-python-implementation-dbf933e64aa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
